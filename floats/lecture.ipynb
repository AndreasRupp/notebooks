{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b31263-6b6d-4c50-9999-8b9ffa84ebb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Floating-point numbers: introduction\n",
    "\n",
    "Equality is tested using `==` and `=` is reserved for variable substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f900463-a068-4345-a626-a127bb0303f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 1 # variable a gets value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f8633-919e-4394-add6-7b99b8314f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a == 1 # check if a is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7b663-75d1-45a3-9ede-ce52afe40f6e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "What does the following cell output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249123ac-5f3d-4548-bc25-f0efafbb8012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "0.1 + 0.1 + 0.1 == 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0249509-bc7e-41b6-ba71-8846e8958654",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "This notebook explains what happens here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d7005-4e02-4b8b-933b-62bc036817dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Binary numbers\n",
    "\n",
    "We are used to the decimal positional system\n",
    "$$\n",
    "\\pi = 3.14159\\dots\n",
    "$$\n",
    "\n",
    "Some rational numbers have infinite decimal expansion\n",
    "\n",
    "$$\n",
    "\\frac 1 3 = 0.333\\dots\n",
    "$$\n",
    "Computers use the binary positional system\n",
    "\n",
    "$$\n",
    "1 \\equiv 1, \\quad 2 \\equiv 10, \\quad 3 \\equiv 11, \\quad 4 \\equiv 100, \\quad \\dots\n",
    "$$\n",
    "\n",
    "Some rational numbers have finite decimal expansion but infinite binary expansion\n",
    "\n",
    "$$\n",
    "\\frac 1 {10} \\equiv 0.00011{\\bf 0011}00110011\\dots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b1897-aa75-4f57-acce-66cfa8033c1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Long division\n",
    "\n",
    "Recall the [long division](https://en.wikipedia.org/wiki/Long_division) algorithm that you have learned in elementary school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56468d36-be29-4acd-87bb-d18a52e290c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def expand_ratio(x, y, max_steps = 10, base = 10):\n",
    "    '''Expand x/y in a base (by default in the decimal base)'''\n",
    "    q, r = divmod(x, y)\n",
    "    output = np.base_repr(q, base)\n",
    "    output += '.'\n",
    "    for n in range(max_steps):\n",
    "        if r == 0:\n",
    "            break\n",
    "        r = base*r\n",
    "        q, r = divmod(r, y)\n",
    "        output += np.base_repr(q, base)\n",
    "    return output\n",
    "    \n",
    "print(expand_ratio(1, 10, base = 10))\n",
    "print(expand_ratio(1, 10, base = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a63ab2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# IEEE 754 floating-point numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6b1be",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "This section is inspired by [Section 15](https://docs.python.org/3/tutorial/floatingpoint.html#floating-point-arithmetic-issues-and-limitations) of the excellent [Python Tutorial](https://docs.python.org/3/tutorial/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edb00e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "Infinite expansions of numbers need to be truncated in computations:\n",
    "\n",
    "* Python uses [IEEE 754 floating-point](https://en.wikipedia.org/wiki/Double-precision_floating-point_format#IEEE_754_double-precision_binary_floating-point_format:_binary64) arithmetic \n",
    "* Numbers are stored using 53 bits (that is, binary digits) of precision\n",
    "  * $2^0 = 1 \\equiv 1$ can be stored using 1 bit, \n",
    "  * $2^1 = 2 \\equiv 10$ and $3 \\equiv 11$  can be stored using 2 bits, \n",
    "  * $2^2 = 4 \\equiv 100, 5, 6$ and $7$  can be stored using 3 bits and so on. \n",
    "\n",
    "On input 0.1 is converted to the closest number of the form $J 2^{-N}$ where \n",
    "$J$ and $N$ are integers that are normalized so that $2^{52} \\le J < 2^{53}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903faa3-f881-45c2-9b0a-9dcab2bc727d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let $x = 0.1$ and write\n",
    "$x \\approx J 2^{-N}$\n",
    "for the best approximation with $J$ satisfying\n",
    "\n",
    "$$\n",
    "2^{52} \\le J < 2^{53}.\n",
    "$$\n",
    "\n",
    "We replace $J$ by $x 2^N$ and take base 2 logarithm, denoted by $\\log_2$,\n",
    "\n",
    "$$\n",
    "52 \\le \\log_2(x) + N < 53.\n",
    "$$\n",
    "\n",
    "This implies that $N$ must be chosen as the smallest integer satisfying \n",
    "\n",
    "$$\n",
    "52 - \\log_2(x) \\le N.\n",
    "$$\n",
    "\n",
    "Equivalently, $N = 52 - n$ where $n$ is the largest integer satisfying\n",
    "\n",
    "$$\n",
    "n \\le \\log_2(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08d8b5-62fd-43ad-a15f-bebcff6f6e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Let's now solve for N and J\n",
    "x = 0.1\n",
    "n = np.floor(np.log2(x))\n",
    "N = 52 - n\n",
    "J = np.round(x * 2**N)\n",
    "print(f'{N = }, {J = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8eb1a-8c0f-4a82-9f6d-d2231db1943c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that J is even so that we can also choose \n",
    "N = N - 1\n",
    "J = J / 2\n",
    "print(f'{N = }, {J = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65be36f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The above normalization explains what _\"Significand precision: 53 bits (52 explicitly stored)\"_ means in the [IEEE 754 floating-point](https://en.wikipedia.org/wiki/Double-precision_floating-point_format#IEEE_754_double-precision_binary_floating-point_format:_binary64) article in Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cb683-e2cf-4f39-8373-cb4a8fde8d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To summarize, when we input 0.1, what the computer actually sees is \n",
    "\n",
    "$$\n",
    "J 2^{-N} = 3602879701896397 \\cdot 2^{-55},\n",
    "$$\n",
    "\n",
    "stored in binary. This number is not exactly 0.1. (It can not be since 0.1 has infinite expansion in binary.) \n",
    "\n",
    "To see the difference, we compare $J$ to\n",
    "$$\n",
    "x 2^N = 0.1 \\cdot 2^N = \\frac{2^N}{10}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45733fc5-6a3a-4159-9f62-a7714b5f1f30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# J = 2^N/10 up to a small remainder\n",
    "q, r = divmod(2**N, 10)\n",
    "print(f'{q = }, {r = }, {J - q = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e255c-e80f-473e-94e3-e0d4a8d9ab7a",
   "metadata": {},
   "source": [
    "We see that $J$ was obtained by rounding up, and that $J 2^{-N}$ is slightly larger than $x = 0.1$. More precisely, \n",
    "\n",
    "$$\n",
    "x 2^N = \\frac{2^N}{10} = q + \\frac{r}{10} = J-1 + \\frac{8}{10} = J - \\frac 1 5,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "J 2^{-N} - x = \\frac 1 5 2^{-N}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4895562-fbdd-4ea9-b6e8-91815d0de215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rounding error is\n",
    "err = 1/5 * 2**(-N)\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304dcd38-722f-4e8d-9581-463790af3bcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limits of floating-points numbers\n",
    "\n",
    "The limits of floating-point numbers are summarized in NumPy as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b9d2b-1c99-4d98-896e-d3699ba27df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.finfo(float))\n",
    "eps = np.finfo(float).eps\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f6822",
   "metadata": {},
   "source": [
    "We rarely want to think in binary, and most of the above limits are given in decimal. For example, `eps` is the [machine epsilon](https://en.wikipedia.org/wiki/Machine_epsilon), that is, the difference between $1$ and the next smallest representable float larger than $1$. We write $x = 1 + \\epsilon$ for this number. \n",
    "Let's compute $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de63594c-aa5c-4788-983b-a5d9b1496804",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Analogously to the above, we let\n",
    "$x = 1 + \\epsilon = J 2^{-N}$.\n",
    "Then $N = 52 - n$ where $n$ is the largest integer satisfying $n \\le \\log_2(x)$.\n",
    "As $x = 1 + \\epsilon$ is close to $1$, $\\log_2(x)$ is close to $0$.\n",
    "Hence $n = 0$ and $N = 52$. Now we can solve for $J$,\n",
    "\n",
    "$$\n",
    "J = 2^N x = 2^N + \\epsilon 2^N.\n",
    "$$\n",
    "\n",
    "We want to find the smallest possible $\\epsilon > 0$, while $J$ is an integer. Hence $J = 2^N + 1$ and \n",
    "\n",
    "$$\n",
    "\\epsilon = 2^{-N} = 2^{-52}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0798c-c91e-4f27-963d-d0056013c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo(float).eps == 2**(-52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf485278-60eb-4744-a1cc-c242da83f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's return to our starting point and check that \n",
    "# 0.1 + 0.1 + 0.1 == 0.3\n",
    "# up to floating-point precision\n",
    "eps = np.finfo(float).eps\n",
    "np.abs(0.1 + 0.1 + 0.1 - 0.3) < eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59ce70-6be8-479e-a300-62b84808da78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rounding error\n",
    "\n",
    "Let $x > 0$ be a real number, and let $J 2^{-N}$ be its best floating-point approximation. (In the case that there are two equally good approximations, we simply choose one of them.) We write again $n$ for the largest integer satisfying $n \\le \\log_2(x)$. Then $N = 52- n$ and\n",
    "\n",
    "$$\n",
    "|x 2^N - J| \\le \\frac 12.\n",
    "$$\n",
    "\n",
    "Therefore, using $2^n \\le 2^{\\log_2(x)} = x$,\n",
    "\n",
    "$$\n",
    "|x - J 2^{-N}| \\le \\frac 12 2^{-N} = \\frac 12 2^{-52} 2^n \\le \\frac \\epsilon 2 x,\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is the machine epsilon. In other words, the _relative rounding error_,\n",
    "\n",
    "$$\n",
    "\\frac{|x - J 2^{-N}|}{x},\n",
    "$$\n",
    "\n",
    "is at most half of the machine epsilon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503abd1-8c18-41c4-890d-4ad8cd193d15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Floating-point operations\n",
    "\n",
    "Finite precision of floating-point numbers will affect the elementary operations $+,-,\\cdot,/$. \n",
    "\n",
    "For simplicity, we consider a model of floating-point numbers that are stored using 8 decimal digits\n",
    "\n",
    "$$\n",
    "\\mathbb F = \\{ \\pm J 10^{-N} : J, N \\in \\mathbb Z,\\ 10^7 \\le J < 10^8 \\}.\n",
    "$$\n",
    "\n",
    "Note that we don't restrict here the size of the exponent $N$. In practice,\n",
    "numbers with too small $-N$ will be rounded to zero, and too large $-N$ will cause an overflow error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9634b8-82a1-4f5a-80fa-583b592d7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2.0**(-1074))\n",
    "print(2.0**(-1075))\n",
    "print(2.0**1023)\n",
    "try:\n",
    "    print(2.0**1024)\n",
    "except OverflowError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb79e4-5498-453a-b492-b07297ee5cdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Addition is modelled by\n",
    "\n",
    "$$\n",
    "x \\oplus y = \\mathrm{fl}(x+y),\n",
    "$$\n",
    "\n",
    "where $\\mathrm{fl}$ rounds to a nearest number in the set $\\mathbb F$, and other floating-point operations are defined analogously. \n",
    "\n",
    "The relative error in floating-point operations, due to rounding, is at most half of the machine epsilon. When reasoning mathematically, this is sometimes called the fundamental axiom of floating point arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042b7d6-1e88-4bc8-84b8-3acc0ef6c1bb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "## Example: sum of three numbers\n",
    "\n",
    "Consider $a,b,c \\in \\mathbb F$ where\n",
    "\n",
    "$$\n",
    "a = 0.23371258 \\cdot 10^{-4}, \n",
    "\\quad \n",
    "b = 0.33678429 \\cdot 10^2,\n",
    "\\quad\n",
    "c = -0.33677811 \\cdot 10^2.\n",
    "$$\n",
    "\n",
    "Let us compute $(a \\oplus b) \\oplus c$ and $a \\oplus (b \\oplus c)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0fcae-d76d-40fb-bc09-8b8c30fd3287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def fl(x, precision = 8):\n",
    "    '''Simulate decimal floating-point rounding with given precision'''\n",
    "    return float(np.format_float_positional(x, \n",
    "        precision = precision, fractional = False))\n",
    "    \n",
    "def oplus(x, y):\n",
    "    return fl(x + y)\n",
    "\n",
    "a = 0.23371258e-4\n",
    "b = 0.33678429e2\n",
    "c = -0.33677811e2\n",
    "print(f'''\n",
    "(1)  {oplus(oplus(a, b), c) = } \n",
    "(2)  {oplus(a, oplus(b, c)) = }\n",
    "optimal = {fl(a + b + c)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405d12b-d2fd-4ee0-9397-c3c67a37631b",
   "metadata": {},
   "source": [
    "As $b$ is much larger than $a$, only the first 3 digits of $a$ contribute to $a \\oplus b$, the rest are lost in the rounding.\n",
    "\n",
    "The second ordering gives the optimal result (obtained by computing the two sums in high precision and rounding only the end result). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220bfe-79a9-4392-bdb1-3a211a79ba12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Catastrophic cancellation\n",
    "\n",
    "In numerical analysis, catastrophic cancellation is the phenomenon that subtracting good approximations to two nearby numbers may yield a very bad approximation to the difference of the original numbers.\n",
    "\n",
    "* Catastrophic cancellation may happen even if the difference is computed exactly\n",
    "* It is not a property of any particular kind of arithmetic like floating-point arithmetic \n",
    "* Rather, it is inherent to subtraction, when the inputs are approximations themselves\n",
    "\n",
    "However, rounding in floating-point operations may amplify the cancellation effect, as happened in case (1) in the above example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066d778",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: subtraction of measured quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4125c8",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This example is taken from [Catastrophic cancellation](https://en.wikipedia.org/wiki/Catastrophic_cancellation) Wikipedia article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bc792-ff15-4da1-999c-d67dd048bee1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Consider two rods of lengths $L_1 = 254.5\\,\\text{cm}$ and $L_2 = 253.5\\,\\text{cm}$. If you measure them with a ruler that is good only to the centimeter, you might get approximations $\\tilde L_1 = 255\\,\\text{cm}$ and $\\tilde L_2 = 253\\,\\text{cm}$. \n",
    "The approximations are in relative error by less than 1% of the true lengths, \n",
    "\n",
    "$$\n",
    "\\frac{|L_1 - \\tilde L_1|}{|L_1|} < 1\\%.\n",
    "$$\n",
    "\n",
    "However, if you subtract the approximate lengths, you will get \n",
    "\n",
    "$$\n",
    "\\tilde L_1 - \\tilde L_2 = 255\\,\\text{cm} - 253\\,\\text{cm} = 2\\,\\text{cm},\n",
    "$$\n",
    "\n",
    "even though the true difference between the lengths is \n",
    "\n",
    "$$\n",
    "L_1 - L_2 = 254.5\\,\\text{cm} - 253.5\\,\\text{cm} = 1\\,\\text{cm}.\n",
    "$$\n",
    "\n",
    "The difference of the approximations is in relative error by 100% of the true difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141e532-5111-481e-8c26-8fefc05b1ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Example: rearranging computations\n",
    "\n",
    "Sometimes it is possible to arrange the operations so that cancellation due to subtraction does not occur. Consider computing $e^x$ via truncation of its Taylor series\n",
    "\n",
    "$$\n",
    "e^x \\approx 1 + x + \\frac{x^2}{2!} + \\dots \\frac{x^n}{n!}.\n",
    "$$\n",
    "\n",
    "Let $x = -10$. We can either simply substitute to the above formula or first use\n",
    "\n",
    "$$\n",
    "e^{-10} = \\frac{1}{e^{10}}\n",
    "$$\n",
    "\n",
    "and then substitute $x = 10$ in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73994c96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def exp_demo(x, n):\n",
    "    '''Compute e^x by using the Taylor series up to the nth term'''\n",
    "    out = 1\n",
    "    xn = 1\n",
    "    cn = 1\n",
    "    for i in range(1, n+1):\n",
    "        xn *= x\n",
    "        cn /= i\n",
    "        out += cn * xn\n",
    "    return out\n",
    "\n",
    "def relative_error(y):\n",
    "    ytrue = np.exp(-10)\n",
    "    return np.abs(y - ytrue) / ytrue\n",
    "\n",
    "ns = range(1, 60)\n",
    "err1 = [relative_error(exp_demo(-10, n)) for n in ns]\n",
    "err2 = [relative_error(1/exp_demo(10, n)) for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe472ab-cfb9-4972-bb49-88869f6601dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.semilogy(ns, err1, 'r')   \n",
    "plt.semilogy(ns, err2, 'b')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('n')\n",
    "ax.set_ylabel('relative error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f20a8-9dbf-4e99-8993-00f3dfd53e3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9 (comp-methods)",
   "language": "python",
   "name": "comp-methods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lo_title": "Floating-point arithmetics",
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
